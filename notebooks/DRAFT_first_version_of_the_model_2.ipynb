{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install / Import all Python Modules Required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DaPSqT6fPMwt",
    "outputId": "ec96648b-6f78-4a86-f1a4-770f657bbab1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in /Users/christianschultes/.pyenv/versions/3.8.12/envs/brief-news/lib/python3.8/site-packages (0.1.73)\r\n",
      "Requirement already satisfied: textsearch>=0.0.21 in /Users/christianschultes/.pyenv/versions/3.8.12/envs/brief-news/lib/python3.8/site-packages (from contractions) (0.0.24)\r\n",
      "Requirement already satisfied: pyahocorasick in /Users/christianschultes/.pyenv/versions/3.8.12/envs/brief-news/lib/python3.8/site-packages (from textsearch>=0.0.21->contractions) (1.4.4)\r\n",
      "Requirement already satisfied: anyascii in /Users/christianschultes/.pyenv/versions/3.8.12/envs/brief-news/lib/python3.8/site-packages (from textsearch>=0.0.21->contractions) (0.3.1)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WGSP1XuGewDX",
    "outputId": "af2f8367-257a-48b9-f314-e02e8e01e0dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Users/christianschultes/.pyenv/versions/3.8.12/envs/brief-news/lib/python3.8/site-packages (0.21.0)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/christianschultes/.pyenv/versions/3.8.12/envs/brief-news/lib/python3.8/site-packages (3.7)\n",
      "Requirement already satisfied: click in /Users/christianschultes/.pyenv/versions/3.8.12/envs/brief-news/lib/python3.8/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: tqdm in /Users/christianschultes/.pyenv/versions/3.8.12/envs/brief-news/lib/python3.8/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: joblib in /Users/christianschultes/.pyenv/versions/3.8.12/envs/brief-news/lib/python3.8/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/christianschultes/.pyenv/versions/3.8.12/envs/brief-news/lib/python3.8/site-packages (from nltk) (2022.10.31)\n"
     ]
    }
   ],
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Ba9EcWEhOvBP"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import string\n",
    "import contractions\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "kXHZoChaOu2c"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Datasets required (Train Set, Validation Set, Test Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "id": "UB7-TFkjOurC",
    "outputId": "9012fe2b-54e8-4f3a-830f-db251790634d"
   },
   "outputs": [],
   "source": [
    "#loading the datasets\n",
    "train_set = pd.read_csv('../raw_data/train.csv')\n",
    "validation_set = pd.read_csv('../raw_data/validation.csv')\n",
    "test_set = pd.read_csv('../raw_data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287113"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Useless Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "id": "SGYMbKSTOudV",
    "outputId": "66d47752-305c-485d-d258-ccd2339b710b"
   },
   "outputs": [],
   "source": [
    "# droppping useless columns\n",
    "train_data = train_set.drop(['id', 'orig_id'], axis=1)[:5000]\n",
    "val_data = validation_set.drop(['id', 'orig_id'], axis=1)[:200]\n",
    "test_data = test_set.drop(['id', 'orig_id'], axis=1)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5Eo0oP9mOuSM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "gZLUT0l6Ot9S"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BAGHDAD, Iraq (CNN) -- The women are too afraid and ashamed to show their faces or have their real names used. They have been driven to sell their bodies to put food on the table for their children -- for as little as $8 a day. Suha, 37, is a mother of three. She says her husband thinks she is cleaning houses when she leaves home. \"People shouldn't criticize women, or talk badly about them,\" says 37-year-old Suha as she adjusts the light colored scarf she wears these days to avoid extremists who insist women cover themselves. \"They all say we have lost our way, but they never ask why we had to take this path.\" A mother of three, she wears light makeup, a gold pendant of Iraq around her neck, and an unexpected air of elegance about her. \"I don't have money to take my kid to the doctor. I have to do anything that I can to preserve my child, because I am a mother,\" she says, explaining why she prostitutes herself. Anger and frustration rise in her voice as she speaks. \"No matter what else I may be, no matter how off the path I may be, I am a mother!\"  Watch a woman describe turning to prostitution to \"save my child\" » . Her clasped hands clench and unclench nervously. Suha's husband thinks that she is cleaning houses when she goes away. So does Karima's family. \"At the start I was cleaning homes, but I wasn't making much. No matter how hard I worked it just wasn't enough,\" she says. Karima, clad in all black, adds, \"My husband died of lung cancer nine months ago and left me with nothing.\" She has five children, ages 8 to 17. Her eldest son could work, but she's too afraid for his life to let him go into the streets, preferring to sacrifice herself than risk her child. She was solicited the first time when she was cleaning an office. \"They took advantage of me,\" she says softly. \"At first I rejected it, but then I realized I have to do it.\" Both Suha and Karima have clients that call them a couple times a week. Other women resort to trips to the market to find potential clients. Or they flag down vehicles. Prostitution is a choice more and more Iraqi women are making just to survive. \"It's increasing,\" Suha says. \"I found this 'thing' through my friend, and I have another friend in the same predicament as mine. Because of the circumstance, she is forced to do such things.\" Violence, increased cost of living, and lack of any sort of government aid leave women like these with few other options, according to humanitarian workers. \"At this point there is a population of women who have to sell their bodies in order to keep their children alive,\" says Yanar Mohammed, head and founder of the Organization for Women's Freedom in Iraq. \"It's a taboo that no one is speaking about.\" She adds, \"There is a huge population of women who were the victims of war who had to sell their bodies, their souls and they lost it all. It crushes us to see them, but we have to work on it and that's why we started our team of women activists.\" Her team pounds the streets of Baghdad looking for these victims often too humiliated to come forward. \"Most of the women that we find at hospitals [who] have tried to commit suicide\" have been involved in prostitution, said Basma Rahim, a member of Mohammed's team. The team's aim is to compile information on specific cases and present it to Iraq's political parties -- to have them, as Mohammed puts it, \"come tell us what [they] are ... going to do about this.\" Rahim tells the heartbreaking story of one woman they found who lives in a room with three of her children: \"She has sex while her three children are in the room, but she makes them stand in separate corners.\" According to Rahim and Mohammed, most of the women they encounter say they are driven to prostitution by a desperate desire for survival in the dangerously violent and unforgiving circumstances in Iraq. \"They took this path but they are not pleased,\" Rahim says. Karima says when she sees her children with food on the table, she is able to convince herself that it's worth it. \"Everything is for the children. They are the beauty in life and, without them, we cannot live.\" But she says, \"I would never allow my daughter to do this. I would rather marry her off at 13 than have her go through this.\" Karima's last happy memory is of her late husband, when they were a family and able to shoulder the hardships of life in today's Iraq together. Suha says as a young girl she dreamed of being a doctor, with her mom boasting about her potential in that career. Life couldn't have taken her further from that dream. \"It's not like we were born into this, nor was it ever in my blood,\" she says. What she does for her family to survive now eats away at her. \"I lay on my pillow and my brain is spinning, and it all comes back to me as if I am watching a movie.\" E-mail to a friend .</td>\n",
       "      <td>Aid workers: Violence, increased cost of living drive women to prostitution .\\nGroup is working to raise awareness of the problem with Iraq's political leaders .\\nTwo Iraqi mothers tell CNN they turned to prostitution to help feed their children .\\n\"Everything is for the children,\" one woman says .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BOGOTA, Colombia (CNN) -- A key rebel commander and fugitive from a U.S. drug trafficking indictment was killed over the weekend in an air attack on a guerrilla encampment, the Colombian military said Monday. Alleged cocaine trafficker and FARC rebel Tomas Medina Caracas in an Interpol photo. Tomas Medina Caracas, known popularly as \"El Negro Acacio,\" was a member of the high command of the Fuerzas Armadas Revolucionarias de Colombia and, according to Colombian and U.S. officials, helped manage the group's extensive cocaine trafficking network. He had been in the cross-hairs of the U.S. Justice Department since 2002. He was charged with conspiracy to import cocaine into the United States and manufacturing and distributing cocaine within Colombia to fund the FARC's 42-year insurgency against the government. U.S. officials alleged Medina Caracas managed the rebel group's sales of cocaine to international drug traffickers, who in turn smuggled it into the United States. He was also indicted in the United States along with two other FARC commanders in November 2002 on charges of conspiring to kidnap two U.S. oil workers from neighboring Venezuela in 1997 and holding one of them for nine months until a $1 million ransom was paid. Officials said the army's Rapid Response Force, backed by elements of the Colombian Air Force, tracked Medina Caracas down at a FARC camp in the jungle in the south of the country. \"After a bombardment, the troops occupied the camp, and they've found 14 dead rebels so far, along with rifles, pistols, communications equipment and ... four GPS systems,\" Defense Minister Juan Manuel Santos said at a news conference. \"The death of 'El Negro Acacio' was confirmed by various sources, including members of FARC itself.\" Medina Caracas commanded FARC's 16th Front in the southern departments of Vichada and Guainia. Established in 1964 as the military wing of the Colombian Communist Party, FARC is Colombia's oldest, largest, most capable and best-equipped Marxist rebel group, according to the U.S. Department of State. E-mail to a friend . Journalist Fernando Ramos contributed to this report.</td>\n",
       "      <td>Tomas Medina Caracas was a fugitive from a U.S. drug trafficking indictment .\\n\"El Negro Acacio\" allegedly helped manage extensive cocaine network .\\nU.S. Justice Department indicted him in 2002 .\\nColombian military: He was killed in an attack on a guerrilla encampment .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               article  \\\n",
       "6  BAGHDAD, Iraq (CNN) -- The women are too afraid and ashamed to show their faces or have their real names used. They have been driven to sell their bodies to put food on the table for their children -- for as little as $8 a day. Suha, 37, is a mother of three. She says her husband thinks she is cleaning houses when she leaves home. \"People shouldn't criticize women, or talk badly about them,\" says 37-year-old Suha as she adjusts the light colored scarf she wears these days to avoid extremists who insist women cover themselves. \"They all say we have lost our way, but they never ask why we had to take this path.\" A mother of three, she wears light makeup, a gold pendant of Iraq around her neck, and an unexpected air of elegance about her. \"I don't have money to take my kid to the doctor. I have to do anything that I can to preserve my child, because I am a mother,\" she says, explaining why she prostitutes herself. Anger and frustration rise in her voice as she speaks. \"No matter what else I may be, no matter how off the path I may be, I am a mother!\"  Watch a woman describe turning to prostitution to \"save my child\" » . Her clasped hands clench and unclench nervously. Suha's husband thinks that she is cleaning houses when she goes away. So does Karima's family. \"At the start I was cleaning homes, but I wasn't making much. No matter how hard I worked it just wasn't enough,\" she says. Karima, clad in all black, adds, \"My husband died of lung cancer nine months ago and left me with nothing.\" She has five children, ages 8 to 17. Her eldest son could work, but she's too afraid for his life to let him go into the streets, preferring to sacrifice herself than risk her child. She was solicited the first time when she was cleaning an office. \"They took advantage of me,\" she says softly. \"At first I rejected it, but then I realized I have to do it.\" Both Suha and Karima have clients that call them a couple times a week. Other women resort to trips to the market to find potential clients. Or they flag down vehicles. Prostitution is a choice more and more Iraqi women are making just to survive. \"It's increasing,\" Suha says. \"I found this 'thing' through my friend, and I have another friend in the same predicament as mine. Because of the circumstance, she is forced to do such things.\" Violence, increased cost of living, and lack of any sort of government aid leave women like these with few other options, according to humanitarian workers. \"At this point there is a population of women who have to sell their bodies in order to keep their children alive,\" says Yanar Mohammed, head and founder of the Organization for Women's Freedom in Iraq. \"It's a taboo that no one is speaking about.\" She adds, \"There is a huge population of women who were the victims of war who had to sell their bodies, their souls and they lost it all. It crushes us to see them, but we have to work on it and that's why we started our team of women activists.\" Her team pounds the streets of Baghdad looking for these victims often too humiliated to come forward. \"Most of the women that we find at hospitals [who] have tried to commit suicide\" have been involved in prostitution, said Basma Rahim, a member of Mohammed's team. The team's aim is to compile information on specific cases and present it to Iraq's political parties -- to have them, as Mohammed puts it, \"come tell us what [they] are ... going to do about this.\" Rahim tells the heartbreaking story of one woman they found who lives in a room with three of her children: \"She has sex while her three children are in the room, but she makes them stand in separate corners.\" According to Rahim and Mohammed, most of the women they encounter say they are driven to prostitution by a desperate desire for survival in the dangerously violent and unforgiving circumstances in Iraq. \"They took this path but they are not pleased,\" Rahim says. Karima says when she sees her children with food on the table, she is able to convince herself that it's worth it. \"Everything is for the children. They are the beauty in life and, without them, we cannot live.\" But she says, \"I would never allow my daughter to do this. I would rather marry her off at 13 than have her go through this.\" Karima's last happy memory is of her late husband, when they were a family and able to shoulder the hardships of life in today's Iraq together. Suha says as a young girl she dreamed of being a doctor, with her mom boasting about her potential in that career. Life couldn't have taken her further from that dream. \"It's not like we were born into this, nor was it ever in my blood,\" she says. What she does for her family to survive now eats away at her. \"I lay on my pillow and my brain is spinning, and it all comes back to me as if I am watching a movie.\" E-mail to a friend .   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           BOGOTA, Colombia (CNN) -- A key rebel commander and fugitive from a U.S. drug trafficking indictment was killed over the weekend in an air attack on a guerrilla encampment, the Colombian military said Monday. Alleged cocaine trafficker and FARC rebel Tomas Medina Caracas in an Interpol photo. Tomas Medina Caracas, known popularly as \"El Negro Acacio,\" was a member of the high command of the Fuerzas Armadas Revolucionarias de Colombia and, according to Colombian and U.S. officials, helped manage the group's extensive cocaine trafficking network. He had been in the cross-hairs of the U.S. Justice Department since 2002. He was charged with conspiracy to import cocaine into the United States and manufacturing and distributing cocaine within Colombia to fund the FARC's 42-year insurgency against the government. U.S. officials alleged Medina Caracas managed the rebel group's sales of cocaine to international drug traffickers, who in turn smuggled it into the United States. He was also indicted in the United States along with two other FARC commanders in November 2002 on charges of conspiring to kidnap two U.S. oil workers from neighboring Venezuela in 1997 and holding one of them for nine months until a $1 million ransom was paid. Officials said the army's Rapid Response Force, backed by elements of the Colombian Air Force, tracked Medina Caracas down at a FARC camp in the jungle in the south of the country. \"After a bombardment, the troops occupied the camp, and they've found 14 dead rebels so far, along with rifles, pistols, communications equipment and ... four GPS systems,\" Defense Minister Juan Manuel Santos said at a news conference. \"The death of 'El Negro Acacio' was confirmed by various sources, including members of FARC itself.\" Medina Caracas commanded FARC's 16th Front in the southern departments of Vichada and Guainia. Established in 1964 as the military wing of the Colombian Communist Party, FARC is Colombia's oldest, largest, most capable and best-equipped Marxist rebel group, according to the U.S. Department of State. E-mail to a friend . Journalist Fernando Ramos contributed to this report.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                    highlights  \n",
       "6  Aid workers: Violence, increased cost of living drive women to prostitution .\\nGroup is working to raise awareness of the problem with Iraq's political leaders .\\nTwo Iraqi mothers tell CNN they turned to prostitution to help feed their children .\\n\"Everything is for the children,\" one woman says .  \n",
       "7                             Tomas Medina Caracas was a fugitive from a U.S. drug trafficking indictment .\\n\"El Negro Acacio\" allegedly helped manage extensive cocaine network .\\nU.S. Justice Department indicted him in 2002 .\\nColombian military: He was killed in an attack on a guerrilla encampment .  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[6:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "U2_3nE9PPC11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data.shape: (5000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"train_data.shape: {train_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if there are any Empty Cells in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ZCCZf26-PDBA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article       0\n",
       "highlights    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "IU72Gu1tPDNK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article       0\n",
       "highlights    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DovhJuAzP3Up"
   },
   "source": [
    "## Dealing with Duplicates / Drop Duplicates in the Train, Validation and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "TLFV9-VNPDiK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "391"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.duplicated(subset=['article', 'highlights']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "QvcTGPr8PDsX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.duplicated(subset=['article', 'highlights']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "rH72px5sPD2m"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.duplicated(subset=['article', 'highlights']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "3mRd9-vZPEAI"
   },
   "outputs": [],
   "source": [
    "def del_duplicates(dataset, columns_to_compare):\n",
    "    '''\n",
    "    Function that deletes duplicated lines comapres according to indicated columns\n",
    "    '''\n",
    "    return dataset.drop_duplicates(subset=columns_to_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "VvulFo2SQARj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4609, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['article', 'highlights']\n",
    "\n",
    "train = del_duplicates(train_data, columns_to_compare=cols)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ifg14tFdQAbj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = del_duplicates(val_data, columns_to_compare=cols)\n",
    "val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "K0I2DFGnQAlV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = del_duplicates(test_data, columns_to_compare=cols)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-obtjbnQMJn"
   },
   "source": [
    "## Potential threshhold for news extraction / Check the Statistical Distribution of Word Counts for Articles and Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Wk1yYboZQA4N"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# word count\n",
    "article_wc = []\n",
    "summary_wc = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in train.article:\n",
    "      article_wc.append(len(i.split()))\n",
    "\n",
    "for i in train.highlights:\n",
    "      summary_wc.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'text':article_wc, 'summary':summary_wc})\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(length_df.text, bins=40)\n",
    "plt.xlabel(\"Word count\")\n",
    "plt.ylabel(\"Number of articles\")\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(length_df.summary, bins=40)\n",
    "plt.xlabel(\"Word count\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OToRGc75QTef"
   },
   "source": [
    "## Clean the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare a Function \"Preprocessing\" to perform the single cleaning steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Transform upper cases to lower cases\n",
    "- Remove return characters, url and html tags\n",
    "- Expand shortened words via Contractions\n",
    "- Remove any parentheses with text inside\n",
    "- Remove special characters, remove whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "DaUHSqf9QBJ6"
   },
   "outputs": [],
   "source": [
    "def preprocessing(sentence: string, remove_stopwords=True) -> string: \n",
    "    \n",
    "    '''\n",
    "    Preprocessing text: lower case, \n",
    "                        deleting punctuation, \n",
    "                        replacing contructions with equivalent,\n",
    "                        deleting stop words,\n",
    "                        removing special characters\n",
    "    '''\n",
    "\n",
    "    # Lowercase\n",
    "    sentence = sentence.lower()\n",
    "   \n",
    "    # Remove return characters, url and html tags\n",
    "    code_list = ['\\n', '\\S*(http|https)\\S*', '\\<a href', '&amp;', '<br />']\n",
    "    for code in code_list:\n",
    "        sentence = re.sub(code, ' ',sentence, flags=re.MULTILINE)\n",
    "    \n",
    "    # expand the shortened words (can't => can not)\n",
    "    # after they will be deleted in stopwords\n",
    "    expanded = []   \n",
    "    for word in sentence.split():\n",
    "        expanded.append(contractions.fix(word, slang=False))\n",
    "        \n",
    "    expanded_sentence = ' '.join(expanded)\n",
    "    \n",
    "    # remove any parenthisis with text inside\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', expanded_sentence)\n",
    "        # Removing punctuation, url and html tags\n",
    "    for punctuation in string.punctuation + '[\\'\\\"]':\n",
    "        sentence = sentence.replace(punctuation, ' ')\n",
    "        \n",
    "    # remove special characters \n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence)\n",
    "\n",
    "    # Removing whitespaces\n",
    "    sentence = sentence.strip()\n",
    "                \n",
    "    if remove_stopwords:\n",
    "        stop_words = set(stopwords.words('english')) ## defining stopwords    \n",
    "        sentence_list = [w for w in sentence.split() if not w in stop_words]\n",
    "        sentence = (' '.join(sentence_list)).strip()\n",
    "        \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGDtjF4bQhjX"
   },
   "source": [
    "### Test the function \"Preprocessing\" prepared to clean the data on a subset to check if it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "gO80ix1OQWFi"
   },
   "outputs": [],
   "source": [
    "def cleaning(dataset: pd.Series, remove_stopwords=True) -> list:\n",
    "    '''\n",
    "    This function creates a cleaned version of each dataset.\n",
    "    Calls the preprocessing function.\n",
    "    '''\n",
    "    \n",
    "    clean = []\n",
    "    for text in dataset:\n",
    "        clean.append(preprocessing(text, remove_stopwords=True))\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "BKamJPHWQWPE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.4 s, sys: 899 ms, total: 23.3 s\n",
      "Wall time: 24.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_train = cleaning(train.article)\n",
    "y_train = cleaning(train.highlights, remove_stopwords=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "RmrmvZSZQWXn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean article : london england harry potter star daniel radcliffe gains access reported million fortune turns monday insists money cast spell daniel radcliffe harry potter harry potter order phoenix disappointment gossip columnists around world young actor says plans fritter cash away fast cars drink celebrity parties plan one people soon turn suddenly buy massive sports car collection something similar told australian interviewer earlier month think particularly extravagant things like buying things cost pounds books cds dvds radcliffe able gamble casino buy drink pub see horror film hostel part ii currently six places number one movie uk box office chart details mark landmark birthday wraps agent publicist comment plans definitely sort party said interview hopefully none reading radcliffe earnings first five potter films held trust fund able touch despite growing fame riches actor says keeping feet firmly ground people always looking say kid star goes rails told reporters last month try hard go way would easy latest outing boy wizard harry potter order phoenix breaking records sides atlantic reprise role last two films watch reporter give review potter latest life beyond potter however londoner filmed tv movie called boy jack author rudyard kipling son due release later year also appear december boys australian film four boys escape orphanage earlier year made stage debut playing tortured teenager peter shaffer equus meanwhile braced even closer media scrutiny legally adult think going sort fair game told reuters e mail friend copyright reuters rights reserved material may published broadcast rewritten redistributed\n",
      "\n",
      "\n",
      "Clean summary : harry potter star daniel radcliffe gets fortune turns monday young actor says plans fritter cash away radcliffe earnings first five potter films held trust fund\n"
     ]
    }
   ],
   "source": [
    "print(f'Clean article : {X_train[0]}')\n",
    "print('\\n')\n",
    "print(f'Clean summary : {y_train[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BFEXlGzDQWg7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 897 ms, sys: 50.8 ms, total: 947 ms\n",
      "Wall time: 1.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_val = cleaning(val.article)\n",
    "y_val = cleaning(val.highlights, remove_stopwords=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ps5m8v4OQpdY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 432 ms, sys: 30.4 ms, total: 462 ms\n",
      "Wall time: 485 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_test = cleaning(test.highlights, remove_stopwords=False)\n",
    "y_test = cleaning(test.article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85bGfFjNQxhV"
   },
   "source": [
    "### !!! Only for target data => adding \"start\" and \"stop\" to the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "s5W6W_maQpvz"
   },
   "outputs": [],
   "source": [
    "def adding_decoder_tokens(data: pd.Series) -> pd.Series:\n",
    "    '''\n",
    "    Adding special tokens for the decoder only to target string\n",
    "    '''\n",
    "    \n",
    "    return pd.Series(data).apply(lambda x : '_START_ '+ x + ' _END_')\n",
    "\n",
    "y_train = adding_decoder_tokens(y_train)\n",
    "y_val = adding_decoder_tokens(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "H7Z0Y7kQQp4G"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_START_ harry potter star daniel radcliffe gets fortune turns monday young actor says plans fritter cash away radcliffe earnings first five potter films held trust fund _END_'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYq42bubQ63S"
   },
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the max len for Article and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "yl7bnjFEQ4BO"
   },
   "outputs": [],
   "source": [
    "# initialize the max len for article and summary\n",
    "max_len_text = 150\n",
    "max_len_summary= 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Article Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k1YDlcmnRAjB"
   },
   "source": [
    "### Transform each Article in articles to a sequence of Integers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of this step are the lists X_train_tok and X_val_tok that basically are lists of tokenized articles in turn being lists of words transformed to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "sGkx77RsQ4WP"
   },
   "outputs": [],
   "source": [
    "# learning the dictionnary from train articles\n",
    "X_tokenizer = Tokenizer()\n",
    "X_tokenizer.fit_on_texts(list(X_train))\n",
    "\n",
    "# Transforms each article in articles to a sequence of integers.\n",
    "X_train_tok = X_tokenizer.texts_to_sequences(X_train) \n",
    "X_val_tok = X_tokenizer.texts_to_sequences(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "P8GHEt9MQ4f-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized article looks like this : \n",
      "[215, 361, 1700, 4990, 486, 2655, 13922, 4923, 886, 120, 72, 4199, 2955, 89, 4924, 112, 1660, 6125, 2655, 13922, 1700, 4990, 1700, 4990, 507, 4645, 5817, 5527, 22570, 76, 23, 209, 1032, 16, 527, 38180, 1361, 178, 1439, 670, 3441, 2459, 1220, 339, 3, 2, 549, 716, 2843, 760, 1362, 1189, 181, 2041, 130, 769, 14, 2101, 22571, 249, 127, 27, 948, 12491, 157, 15, 2221, 157, 699, 1410, 1226, 14786, 10382, 13922, 217, 11884, 5635, 760, 3441, 7842, 43, 4406, 283, 8277, 80, 1348, 1084, 168, 1039, 179, 3, 397, 1010, 1194, 117, 6493, 846, 781, 6009, 2379, 13164, 1929, 4530, 1060, 527, 1960, 1349, 165, 1, 440, 3528, 1878, 2166, 13922, 7634, 18, 113, 4990, 1138, 269, 1389, 1580, 217, 2401, 496, 875, 2743, 8741, 1032, 16, 1686, 685, 7261, 553, 2, 220, 346, 35, 2656, 486, 783, 22572, 14, 625, 22, 127, 414, 288, 61, 47, 4, 924, 770, 10829, 601, 10830, 1700, 4990, 507, 4645, 2028, 1246, 1358, 2657, 20208, 521, 22, 8, 1138, 25, 1961, 234, 1430, 4990, 770, 48, 1168, 4990, 250, 38181, 5451, 459, 397, 71, 601, 1735, 1025, 30356, 30357, 325, 858, 392, 135, 9, 7, 1126, 571, 1677, 2101, 283, 78, 1677, 1850, 6936, 249, 9, 45, 794, 3131, 803, 4925, 3930, 1440, 38182, 38183, 1000, 20209, 49, 2363, 277, 6010, 4256, 1871, 27, 34, 1349, 1403, 419, 14, 4257, 105, 151, 125, 1479, 4257, 185, 1322, 1471, 40, 919, 1472, 3753, 3796]\n"
     ]
    }
   ],
   "source": [
    "print('Tokenized article looks like this : ')\n",
    "print(X_train_tok[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pad the Tokenized Articles to max_len_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The padding step shall ensure that all tokenized articles are split in a way that the results are lists of integers all having the same length max_len_text\n",
    "- If a tokenized article is longer than max_len_text it is truncated\n",
    "- If a tokenized article is shorter than max_len_text it is filled with 0's to reach a length of max_len_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "XaRpUF6UQWpO"
   },
   "outputs": [],
   "source": [
    "# post-padding with zeros up to maximum length\n",
    "X_train_pad = pad_sequences(X_train_tok, dtype='float32', maxlen=max_len_text, padding='post') \n",
    "X_val_pad = pad_sequences(X_val_tok, dtype='float32', maxlen=max_len_text, padding='post')\n",
    "\n",
    "X_vocab = len(X_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "0uj0QmuwRHCO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of train articles vocabulary is 56317\n"
     ]
    }
   ],
   "source": [
    "print(f'The size of train articles vocabulary is {X_vocab}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LbWq5nCdRbhq"
   },
   "source": [
    "## Summary Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Summaries to lists of Integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "d8L4ZtTpRHSm"
   },
   "outputs": [],
   "source": [
    "# learning the dictionnary from train summaries\n",
    "y_tokenizer = Tokenizer()\n",
    "y_tokenizer.fit_on_texts(list(y_train))\n",
    "\n",
    "# Transforms each summary in summaries to a sequence of integers.\n",
    "y_train_tok = y_tokenizer.texts_to_sequences(y_train) \n",
    "y_val_tok = y_tokenizer.texts_to_sequences(y_val) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pad the tokenized Summaries to a Length of max_len_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "60Evu6O4RHeV"
   },
   "outputs": [],
   "source": [
    "# post-padding with zeros up to maximum length\n",
    "y_train_pad = pad_sequences(y_train_tok, dtype='float32', maxlen=max_len_summary, padding='post')\n",
    "y_val_pad = pad_sequences(y_val_tok,  dtype='float32', maxlen=max_len_summary, padding='post')\n",
    "\n",
    "y_vocab = len(y_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "KLKOzFNKRH_G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of train summary vocabulary is 18463\n"
     ]
    }
   ],
   "source": [
    "print(f'The size of train summary vocabulary is {y_vocab}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Model that will be Trained and will Predict Summaries of Articles based on the Training Performed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules Potentially Required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "5BHCPHk3Zfq_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from tensorflow.keras import optimizers\n",
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import re           \n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords   \n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional, Attention\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define latent_dim & embedding_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- latent_dim is the dimension intended for the output of the Encoder, i.e. the first step of the Model\n",
    "- embedding_dim is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "k8-MdhYBo9oC"
   },
   "outputs": [],
   "source": [
    "latent_dim = 500\n",
    "embedding_dim = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TmpIHCQqRxdk"
   },
   "source": [
    "--------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6jzYbuaHh0XH"
   },
   "source": [
    "## Step 1 of the Model: Embed the Inputs to the Encoder into the Latent Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Encoder allocates the integers (being included in the tokenized and padded lists of integers) inserted into the Model into Vectors in the \"Latent Space\"\n",
    "- Input shape is max_len_text as via the step before we have padded the lists of integers to a length of max_len_text\n",
    "- X_Vocab is the length of the X_Tokenizer Word Index + 1, i.e. the number of integers + 1. Why \"+1\"? xxx\n",
    "- latent_dim is the dimensionality of the output space\n",
    "- The result of the Encoder, \"enc_emb\", is a Tensor having the shape (None, 300, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "t7Zf8IJdhlpc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-03 14:05:34.565827: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Add documentation for encoder\n",
    "# shape: max_len_text, i.e. the maximum length of words of the input text we will insert into the model, correct?\n",
    "# Embedding: X_vocab is the length of the X_Tokenizer Word Index + 1\n",
    "# Embedding: latent_dim is the dimensionality of the output space\n",
    "\n",
    "encoder_inputs = Input(shape=(max_len_text,)) \n",
    "enc_emb = Embedding(X_vocab, latent_dim,trainable=True)(encoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 150, 500) dtype=float32 (created by layer 'embedding')>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJ9TKv9zib6y"
   },
   "source": [
    "## Step 2 of the Model: Three Stages of Stacked Long Short Term Memory (LSTM) Acting as the Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three LSTM layers\n",
    "\n",
    "The outputs of this step are\n",
    "\n",
    "- encoder_outputs being a tensor with shape (None, max_len_text, max_len_text)\n",
    "- state_h being a tensor with shape (none, max_len_text)\n",
    "- state_c being a tensor with shape (none, max_len_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "KRFKSPDjiaEI"
   },
   "outputs": [],
   "source": [
    "# LSTM 1 \n",
    "# first integer shown in the brackets is the \"dimensionality of the output space\". so, that would be the length of the output summary, right?\n",
    "# return_sequences = Boolean. Whether to return the last output in the output sequence, or the full sequence. Default: False.\n",
    "# return_state = Boolean. Whether to return the last state in addition to the output. Default: False.\n",
    "\n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
    "\n",
    "#LSTM 2 \n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
    "\n",
    "#LSTM 3 \n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True) \n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 150, 500) dtype=float32 (created by layer 'lstm')>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_output1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 150, 500) dtype=float32 (created by layer 'lstm_1')>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 150, 500) dtype=float32 (created by layer 'lstm_2')>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 500) dtype=float32 (created by layer 'lstm_2')>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 500) dtype=float32 (created by layer 'lstm_2')>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 150, 500) dtype=float32 (created by layer 'lstm_2')>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDWYA9T-is-v"
   },
   "source": [
    "## Step 3 of the Model: Setup the Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "VoYbT4rAia4x"
   },
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None,)) \n",
    "dec_emb_layer = Embedding(y_vocab, latent_dim,trainable=True) \n",
    "dec_emb = dec_emb_layer(decoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, None, 500) dtype=float32 (created by layer 'embedding_1')>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fsTzUy0cjgAN"
   },
   "source": [
    "Decoder based on encoder_states as initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "MBx3LRh5jkeV"
   },
   "outputs": [],
   "source": [
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iNipeqwZj5lB"
   },
   "source": [
    "Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "OUd41C8_jlMc"
   },
   "outputs": [],
   "source": [
    "#attn_layer = Attention(name='attention_layer') \n",
    "#attn_out = attn_layer([encoder_outputs, decoder_outputs]) \n",
    "\n",
    "attention = Attention(name='attention_layer')\n",
    "attn_out = attention([decoder_outputs, encoder_outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, None, 500) dtype=float32 (created by layer 'lstm_3')>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 150, 500) dtype=float32 (created by layer 'lstm_2')>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQuvnGixkDfM"
   },
   "source": [
    "Concatenate attention output and decoder LSTM output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "dCjlmO-VkGuW"
   },
   "outputs": [],
   "source": [
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, None, 1000) dtype=float32 (created by layer 'concat_layer')>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_concat_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M93_0V5TkbkJ"
   },
   "source": [
    "Add a Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "Xu59RA5pkHDh"
   },
   "outputs": [],
   "source": [
    "#decoder_dense = Dense(y_vocab, activation='softmax')\n",
    "decoder_dense = TimeDistributed(Dense(y_vocab, activation='softmax')) \n",
    "#decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_outputs = decoder_dense(decoder_concat_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, None, 18463) dtype=float32 (created by layer 'time_distributed')>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srb_Kzsikj1S"
   },
   "source": [
    "Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "hXFVF-5xkHX7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 150)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 150, 500)     28158500    ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 150, 500),   2002000     ['embedding[0][0]']              \n",
      "                                 (None, 500),                                                     \n",
      "                                 (None, 500)]                                                     \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 150, 500),   2002000     ['lstm[0][0]']                   \n",
      "                                 (None, 500),                                                     \n",
      "                                 (None, 500)]                                                     \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 500)    9231500     ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 150, 500),   2002000     ['lstm_1[0][0]']                 \n",
      "                                 (None, 500),                                                     \n",
      "                                 (None, 500)]                                                     \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, None, 500),  2002000     ['embedding_1[0][0]',            \n",
      "                                 (None, 500),                     'lstm_2[0][1]',                 \n",
      "                                 (None, 500)]                     'lstm_2[0][2]']                 \n",
      "                                                                                                  \n",
      " attention_layer (Attention)    (None, None, 500)    0           ['lstm_3[0][0]',                 \n",
      "                                                                  'lstm_2[0][0]']                 \n",
      "                                                                                                  \n",
      " concat_layer (Concatenate)     (None, None, 1000)   0           ['lstm_3[0][0]',                 \n",
      "                                                                  'attention_layer[0][0]']        \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, None, 18463)  18481463   ['concat_layer[0][0]']           \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 63,879,463\n",
      "Trainable params: 63,879,463\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dec_tr_data = dec_data.reshape(len(dec_data),max_tr_len,1)[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-03 14:05:50.789890: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 1200 num_cores: 4 environment { key: \"cpu_instruction_set\" value: \"SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 4194304 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/154 [========================>.....] - ETA: 3:41 - loss: 8.1452"
     ]
    }
   ],
   "source": [
    "#opt = optimizers.RMSprop(learning_rate=0.00001)\n",
    "model.compile( \n",
    "    #optimizer = opt, loss=\"sparse_categorical_crossentropy\")\n",
    "    optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\") \n",
    "history = model.fit( \n",
    "    [X_train_pad,y_train_pad[:,:-1]],\n",
    "    y_train_pad.reshape(len(y_train_pad), max_len_summary, 1)[:,1:], \n",
    "    batch_size=30, \n",
    "    epochs=10,\n",
    "    #callbacks=[es],\n",
    "    validation_data=([X_val_pad,y_val_pad[:,:-1]], y_val_pad.reshape(y_val_pad.shape[0],y_val_pad.shape[1], 1)[:,1:])\n",
    "    #validation_split=0.1,\n",
    "    )\n",
    " \n",
    "#Save model\n",
    "model.save(\"s2s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pvZgxhtYp5AY"
   },
   "source": [
    "Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eoFU_xuzp7nj"
   },
   "outputs": [],
   "source": [
    "#model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPBvSyGNqDlq"
   },
   "source": [
    "Implement Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yPe0pDCJqGIF"
   },
   "outputs": [],
   "source": [
    "#es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08_8l-KVqL0F"
   },
   "source": [
    "Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history=model.fit([X_train_pad,y_train_pad[:,:-1]], \n",
    "                #  y_train_pad.reshape(len(y_train_pad), max_len_summary, 1)[:,1:],\n",
    "                 # epochs=50,callbacks=[es],batch_size=512, \n",
    "                  #validation_data=([X_val_pad,y_val_pad[:,:-1]], \n",
    "                   #                y_val_pad.reshape(y_val_pad.shape[0], y_val_pad.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VuCD-guTqOdU"
   },
   "outputs": [],
   "source": [
    "#history=model.fit([X_train_pad,y_train_pad[:,:-1]], \n",
    " #                 y_train_pad.reshape(y_train_pad.shape[0], y_train_pad.shape[1], 1)[:,1:],\n",
    "  #                epochs=50,callbacks=[es],batch_size=512, \n",
    "   #               validation_data=([X_val_pad,y_val_pad[:,:-1]], \n",
    "    #                               y_val_pad.reshape(y_val_pad.shape[0], y_val_pad.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_njDl36rgcV"
   },
   "source": [
    "Diagnostics enabling us to check the course of losses for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jx2m8536reeq"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot \n",
    "pyplot.plot(history.history['loss'], label='train') \n",
    "pyplot.plot(history.history['val_loss'], label='test') \n",
    "pyplot.legend() \n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_target_word_index=y_tokenizer.index_word \n",
    "reverse_source_word_index=X_tokenizer.index_word \n",
    "target_word_index=y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XGZwLW2uuYJk"
   },
   "source": [
    "Inference Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7H43DR6GrfBX"
   },
   "outputs": [],
   "source": [
    "# encoder inference\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# decoder inference\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_len_text,latent_dim))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2= dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "#attention inference\n",
    "attention = model.layers[8]\n",
    "attn_out_inf = attention([decoder_outputs2, decoder_hidden_state_input])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "#decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "[decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_hidden_state_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6XYmfk_uvh9"
   },
   "source": [
    "Function implementing the Inference Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IdAbshrtupvu"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "\n",
    "    # Chose the 'start' word as the first word of the target sequence\n",
    "    target_seq[0, 0] = target_word_index['start']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "\n",
    "        if(sampled_token!='end'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "            # Exit condition: either hit max length or find stop word.\n",
    "            if (sampled_token == 'end' or len(decoded_sentence.split()) >= (max_len_summary-1)):\n",
    "                stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vhaan0Flvj3n"
   },
   "source": [
    "Function to transform Integers back to Words for our source sequence of Words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I69Av6tiu5u_"
   },
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=target_word_index['start']) and i!=target_word_index['end']):\n",
    "            newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6evXjT7hxIkg"
   },
   "source": [
    "Function to transform Integers back to Words for our target sequence of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M0F0tGIdu6FO"
   },
   "outputs": [],
   "source": [
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+reverse_source_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_H1YE2BYxZnF"
   },
   "source": [
    "Show the Output of our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-7JJHUkhu6aN"
   },
   "outputs": [],
   "source": [
    "for i in range(len(X_val_pad)):\n",
    "    print(\"Review:\",seq2text(X_val_pad[i]))\n",
    "    print(\"Original summary:\",seq2summary(y_val_pad[i]))\n",
    "    print(\"Predicted summary:\",decode_sequence(X_val_pad[i].reshape(1,max_len_text)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zQqNZb9ru6kt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6wJnyNWvu6vL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
